# Control, See: Guided Text-to-Image Generation via In-context Reference Representation

Guided text-to-image generation deals with the task of generating images from textual descriptions while constraining the output generation using a set of references. Typically, this reference consists of a set of RGB images, depicting the desired characteristics of the generated image. Motivation for this may include style transfer, character consistency, etc. However, it is relatively difficult to maintain similar comformity to a reference when it is provided in the form of text. In this work, I explore guided generation of images from textual descriptions with in-context reference representation. To demonstrate the effectiveness of the approach, I present a series of images generated using DALL E 3 and showcase its ability to retain character consistency and scene genre preservation across multiple generations.

The following catalogue primarily presents a key frame storyboard in cinematic style for a short story of one particular genre -- horror. Additionally, a curated set of images generated with a different style (cartoons) and an alternate genre (Rom-Com, Indo-Western) are also showcased. Last but not the least, keeping in line with the theme of the content, a few blooper outputs are also included in this list. The album is divided into multiple sections, each containing a set of images generated from a single prompt. Prompts are designed to contain (a) thematic description: style of the image ahd desired genre, (b) scene description: background, foreground, etc., and (c) detailed character descriptions: facial features, attire, pose, etc.
